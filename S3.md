# S3

## Buckets

- Must have globally unique name.
- Store objects (files) in directories (buckets)
- Buckets are defined at the region level
- Naming convention:
  - No uppercase
  - No underscore
  - 3-63 characters long
  - Not an IP

## Objects

- Objects have a key.
- URL = full path, s3://mybucket/my_folder/filename.txt
- There is no concept of directories.
- Multi part upload and max size 100mb.

## S3 Versioning

- You have to enable it.
- Same key overwrite will increment the version.
- Prevents accidental delete as it only deletes a marker.
- You can manually delete a version of the object.

## S3 Encryption

- 4 Methods of encryption:
  - SSE-S3: encrypts objects using keys handled & managed by AWS
    - Object is encrypted server side
    - header must be set aws:sse
  - SSE-KMS: leverages AWS key management service to manage encryption keys
    - Object is encrypted server side
    - header must be set aws:kms
    - full control of rotation policy
    - KMS advantages: user control + audit trail
  - SSE-C: you manage your own encryption keys
    - AWS s3 does not store the encryption key you provided
    - Encryption key must be provided in HTTP header
    - To retrieve you need to provide same encryption key
  - Client Side Encryption
    - Client Library such as Amazon S3 Encryption Client
    - Clients must encrypt data before sending to S3
    - Clients must decrypt data themselves when retrieving s3
    - Customer fully manages the keys and encryption cycle

## Security

- User based
- Resource based
  - Bucket Policies: bucket wide rules from s3 console
    - JSON based policies (statement.sid|effect|principal|action|resource)
- Block Public Access
  - 4 options etc.
- Networking: Supports VPC endpoints
- Logging and Audit: S3 Access Logs can be stored in S3 Bucket
- API calls can be logged in AWS Cloudtrail
- User security:
  - MFA delete (in versioned objects)
  - Pre-Signed URLs: URLs that are valid only for a limited time

## S3 Websites

- Need to make public bucket.
- Need to add Bucket Policy to allow everyone to get object.

## S3 Cors

- Origin: scheme (protocol) + host (domain) + port
  - https://www.example.com => https (scheme) + www.example.com (host) + 443 (port, implied)
- CORS: Cross Origin Resource Sharing
- Web Browser based mechanism. Can make request from origin A only if origin B allows it.
- Access-Control-Allow-Origin => must be allowed by origin B.
- Preflight request (OPTIONS) => returns preflight response

## Consistency Model

- Read after write consistency for PUTS of new objects.
- PUT 200 -> GET 200
- GET 404 -> PUT 200 -> GET 404 (eventually consistent)
- DELETE 200 -> GET 200 (if you do it very fast, eventually consistent)
- PUT 200 -> PUT 200 -> GET 200 (can get old version)
- No way to ensure STRONG CONSISTENCY.

## MFA Delete

- Only root account can enable it.
- Can only be enabled using CLI.
- S3 Bucket needs versioning enabled.


## Default Encryption vs Bucket Policy

- Old way for default encryption was to add bucket policy with header conditions on putObject. If encryption header not present do not allow putObject.
- New way: Use default encryption option in S3 settings.
- Bucket policies are evaluated before default encryption.

## Access Logs

- Any request made to s3 will be logged and logs sent to target s3 bucket.
- Data can be analyzed using analytic tools such as AWS Athena.
- WARNING: Do not set same bucket as target bucket. It creates an infinite loop.

## Replication

- Must enable versioning.
- Buckets can be in different accounts.
- CRR (cross-region replication) & SSR (same-region replication)
- CRR use cases:  compliancy, lower latency, replication across accountsA
- SSR use cases: live replication between test and production accounts etc.
- Replication is not chained. Bucket 1 => Bucket 2 => Bucket 3


## S3 Pre-Signed URLs

- Users are given pre-signed URLs with which they can make GET / PUT requests.
- Examples:
  - Allow only logged in users to download premium video on s3 bucket
  - Allow constantly changing list of users to download content


## S3 Storage Tiers + Glacier

- S3 General Purpose
- S3 IA (Infrequent Access)
- S3 One Zone IA
- S3 Intelligent Tiering
- Glacier
  - 3 retrieval options: expedited, standard, bulk 
  - minimum storage days: 90
- Glacier Deep Archive
  - 2 retrieval options: standard, bulk 
  - minimum storage days: 180


## Lifecycle Policies

- Transition actions:
  - Move objects from S3 General Purpose to S3 IA after 60 days.
  - Move objects from S3 IA to Glacier after 6 months.
- Expiration actions:
  - Access logs can be set to delete after 365 days.
  - Can be used to delete old versions of files if versioning is enabled.
  - Can be used to delete incomplete multi-part uploads.
- Rules can be done for certain 'directories'

## Performance

- Multi-Part upload:
  - Recommended for files > 100 mb, must use for files > 5 GB.
  - Can help paralelize uploads (speed up transfers)
- S3 Transfer Accelaration

## Event Notifications

- Action triggest events.
- Example: after S3:PutObject with filename (*.jpg) create thumbnail.

## AWS Athena

- Serverless service to perfform analytics directly against s3 files
- Uses SQL language to query the files.
- Analyze logs
- Analyze data directly on S3.